import os
import re
import logging
import base64
from email.utils import parsedate_to_datetime
from googleapiclient.discovery import build
from google.oauth2.credentials import Credentials

# Constants to match JOTA emails (adjust if needed)
FLAGGED_QUERY = "is:starred subject:(JOTA)"
WEEKLY_OVERVIEW_QUERY = 'subject:"JOTA - Weekly Overview Of Your Assignments"'

class JOTAJournal:
    def __init__(self, gmail_service, user_id="me", debug=True):
        """
        gmail_service: authenticated Gmail API service object
        user_id: Gmail user ID, usually "me"
        """
        self.service = gmail_service
        self.user_id = user_id
        self.debug = debug

    def log(self, msg):
        if self.debug:
            print(f"[JOTA] {msg}")

    def list_messages(self, query):
        """List message IDs matching the query"""
        messages = []
        request = self.service.users().messages().list(userId=self.user_id, q=query)
        while request is not None:
            response = request.execute()
            msgs = response.get('messages', [])
            messages.extend(msgs)
            request = self.service.users().messages().list_next(request, response)
        self.log(f"Found {len(messages)} messages for query: {query}")
        return messages

    def get_message(self, msg_id):
        """Fetch full message content and headers"""
        msg = self.service.users().messages().get(userId=self.user_id, id=msg_id, format='full').execute()
        payload = msg.get('payload', {})
        headers = payload.get('headers', [])
        subject = self._get_header(headers, 'Subject')
        date_str = self._get_header(headers, 'Date')
        date = None
        try:
            date = parsedate_to_datetime(date_str)
        except Exception:
            date = None

        body = self._extract_body(payload)

        return subject, body, date

    def _get_header(self, headers, name):
        for h in headers:
            if h['name'].lower() == name.lower():
                return h['value']
        return ""

    def _extract_body(self, payload):
        # Prefer text/plain part or raw body data
        if 'parts' in payload:
            for part in payload['parts']:
                if part.get('mimeType') == 'text/plain':
                    data = part.get('body', {}).get('data')
                    if data:
                        return base64.urlsafe_b64decode(data).decode('utf-8', errors='ignore')
        body_data = payload.get('body', {}).get('data')
        if body_data:
            return base64.urlsafe_b64decode(body_data).decode('utf-8', errors='ignore')
        return ""

    def parse_acceptance_email(self, subject, body, date):
        """Parse flagged acceptance email"""
        # Example manuscript ID in subject: "JOTA-D-24-00769R1"
        ms_id_match = re.search(r'JOTA-D-\d{2}-\d{5}R?\d*', subject)
        ms_id = ms_id_match.group(0) if ms_id_match else None

        # Extract referee name from body, e.g. "Olivier Menoukeu Pamen, Ph.D has agreed"
        referee_match = re.search(r"([A-Z][a-zA-Z\s\.\-']{2,}),?\s*(Ph\.D\.?|PhD|MD)?\s*has agreed", body, re.IGNORECASE)
        referee_name = referee_match.group(1).strip() if referee_match else None

        return {
            "type": "acceptance",
            "manuscript_id": ms_id,
            "referee_name": referee_name,
            "date": date,
            "subject": subject,
            "body": body,
        }

    def parse_invitation_email(self, subject, body, date):
        """Parse flagged invitation email"""
        # Extract manuscript ID in body or subject
        ms_id_match = re.search(r'JOTA-D-\d{2}-\d{5}R?\d*', subject + " " + body)
        ms_id = ms_id_match.group(0) if ms_id_match else None

        # Referee name usually in body near "Dear Prof. NAME," or "Dear Dr. NAME,"
        referee_match = re.search(r"Dear\s+(Prof\.|Dr\.|Mr\.|Ms\.)?\s*([A-Z][a-zA-Z\s\.\-']+),", body)
        referee_name = referee_match.group(2).strip() if referee_match else None

        # Title extraction (simplified, may be multiline)
        title_match = re.search(r'for the article "(.+?)"', body, re.IGNORECASE | re.DOTALL)
        title = title_match.group(1).strip() if title_match else None

        return {
            "type": "invitation",
            "manuscript_id": ms_id,
            "referee_name": referee_name,
            "title": title,
            "date": date,
            "subject": subject,
            "body": body,
        }

    def parse_weekly_overview_email(self, subject, body, date):
        """Parse unflagged weekly overview email with manuscript statuses"""
        # Manuscripts listed like:
        # JOTA-D-24-00769R1  submitted 288 days ago  Under Review (31 days) 1 Agreed ...
        # Title: Maximum principle of stochastic optimal control problems with model uncertainty
        # Authors: Tao Hao , Shandong University of Finance and Economics; ...

        ms_pattern = re.compile(
            r"(JOTA-D-\d{2}-\d{5}R?\d*)\s+submitted.*?Title:\s*(.+?)\s*Authors:\s*(.+?)(?=(JOTA-D-|$))",
            re.DOTALL
        )

        manuscripts = []
        for match in ms_pattern.finditer(body):
            ms_id = match.group(1).strip()
            title = match.group(2).strip().replace('\n', ' ').replace('\r', '')
            authors = match.group(3).strip().replace('\n', ' ').replace('\r', '')
            manuscripts.append({
                "manuscript_id": ms_id,
                "title": title,
                "authors": authors,
            })

        return {
            "type": "weekly_overview",
            "date": date,
            "subject": subject,
            "body": body,
            "manuscripts": manuscripts,
        }

    def fetch_and_parse_emails(self):
        """
        Fetch all flagged acceptance and invitation emails, and weekly overview emails,
        then parse and combine them into a single data structure.
        """
        # Fetch flagged emails (acceptance + invitation)
        flagged_msgs = self.list_messages(FLAGGED_QUERY)
        flagged_data = []
        for msg in flagged_msgs:
            subject, body, date = self.get_message(msg['id'])
            if "Reviewer has agreed to review" in subject:
                flagged_data.append(self.parse_acceptance_email(subject, body, date))
            elif "Reviewer Invitation for" in subject:
                flagged_data.append(self.parse_invitation_email(subject, body, date))

        # Fetch weekly overview emails (unflagged)
        weekly_msgs = self.list_messages(WEEKLY_OVERVIEW_QUERY)
        weekly_data = []
        for msg in weekly_msgs:
            subject, body, date = self.get_message(msg['id'])
            weekly_data.append(self.parse_weekly_overview_email(subject, body, date))

        # Cross-check / merge data here as needed; for now just return separately
        return {
            "flagged_emails": flagged_data,
            "weekly_overviews": weekly_data
        }

    def scrape_manuscripts_and_emails(self):
        """
        Entry point to run full email-only scraping for JOTA.
        """
        self.log("Starting email scraping for JOTA.")
        try:
            data = self.fetch_and_parse_emails()
            self.log(f"Scraped {len(data['flagged_emails'])} flagged emails and {len(data['weekly_overviews'])} weekly overview emails.")
            return data
        except Exception as e:
            logging.error(f"[JOTA] Email scraping failed: {e}")
            return {}