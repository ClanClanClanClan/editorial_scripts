#!/usr/bin/env python3
"""
Production SIFIN Extractor

Real working implementation for SIAM Journal on Financial Mathematics (SIFIN).
Replaces the fake stub with actual extraction functionality.
"""

import os
import re
import time
import json
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.firefox.options import Options
from selenium.common.exceptions import TimeoutException, WebDriverException

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SIFINExtractor:
    """Real SIFIN extractor for SIAM Journal on Financial Mathematics."""
    
    def __init__(self):
        self.base_url = "http://sifin.siam.org/"
        self.journal_code = "SIFIN"
        self.journal_name = "SIAM Journal on Financial Mathematics"
        self.driver = None
        self.wait = None
        
        # Extraction results
        self.manuscripts = []
        self.extraction_metadata = {}
        
        logger.info(f"ðŸ”§ Initialized {self.journal_name} extractor")
    
    def setup_driver(self):
        """Setup Firefox driver with appropriate options for SIFIN."""
        options = Options()
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--width=1920')
        options.add_argument('--height=1080')
        
        # SIFIN-specific browser settings
        options.set_preference("general.useragent.override", 
                              "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36")
        options.set_preference("dom.webdriver.enabled", False)
        options.set_preference("useAutomationExtension", False)
        
        # Enable downloads
        download_dir = str(Path.cwd() / "downloads")
        options.set_preference("browser.download.folderList", 2)
        options.set_preference("browser.download.manager.showWhenStarting", False)
        options.set_preference("browser.download.dir", download_dir)
        options.set_preference("browser.helperApps.neverAsk.saveToDisk", "application/pdf,text/plain")
        
        try:
            self.driver = webdriver.Firefox(options=options)
            self.wait = WebDriverWait(self.driver, 30)
            logger.info("âœ… Firefox driver setup completed")
            return True
        except WebDriverException as e:
            logger.error(f"âŒ Failed to setup Firefox driver: {e}")
            return False
    
    def authenticate_with_orcid(self) -> bool:
        """Authenticate with SIFIN using ORCID."""
        try:
            logger.info("ðŸ” Starting ORCID authentication...")
            
            # Navigate to SIFIN main page
            self.driver.get(self.base_url)
            time.sleep(3)
            
            # Handle potential Cloudflare challenge
            self._handle_cloudflare_challenge()
            
            # Look for ORCID login button using multiple selectors
            orcid_selectors = [
                "a[href*='sso_site_redirect'][href*='orcid']",
                "img[src*='orcid']",
                "img[title='ORCID']", 
                "a img[src*='orcid_32x32.png']",
                "a[href*='orcid']",
                ".orcid-login",
                "input[value*='ORCID']"
            ]
            
            orcid_element = None
            for selector in orcid_selectors:
                try:
                    orcid_element = self.wait.until(
                        EC.element_to_be_clickable((By.CSS_SELECTOR, selector))
                    )
                    logger.info(f"âœ… Found ORCID element with selector: {selector}")
                    break
                except TimeoutException:
                    continue
            
            if not orcid_element:
                logger.error("âŒ No ORCID login element found")
                return False
            
            # Click ORCID element (button or image)
            if orcid_element.tag_name == 'img':
                # If it's an image, click its parent link
                orcid_link = orcid_element.find_element(By.XPATH, "./..")
                orcid_link.click()
            else:
                orcid_element.click()
            
            time.sleep(2)
            
            # Handle ORCID authentication process
            logger.info("â³ Waiting for ORCID authentication to complete...")
            logger.info("   ðŸ’¡ Please complete ORCID login manually in the browser")
            
            # Wait for successful authentication
            authenticated = self._wait_for_authentication()
            
            if authenticated:
                logger.info("âœ… ORCID authentication successful")
                return True
            else:
                logger.error("âŒ ORCID authentication timeout")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ORCID authentication failed: {e}")
            return False
    
    def _handle_cloudflare_challenge(self):
        """Handle Cloudflare challenge if present."""
        try:
            # Check for Cloudflare challenge
            page_source = self.driver.page_source.lower()
            if 'cloudflare' in page_source or 'challenge' in page_source:
                logger.info("ðŸ›¡ï¸ Cloudflare challenge detected - waiting...")
                time.sleep(10)  # Wait for challenge to complete
                
        except Exception as e:
            logger.warning(f"âš ï¸ Cloudflare handling warning: {e}")
    
    def _wait_for_authentication(self) -> bool:
        """Wait for authentication to complete."""
        # Dashboard indicators for SIFIN
        dashboard_indicators = [
            "associate editor",
            "manuscripts",
            "reviews", 
            "editorial",
            "sifin",
            "financial mathematics"
        ]
        
        for i in range(60):  # Wait up to 60 seconds
            try:
                page_source = self.driver.page_source.lower()
                if any(indicator in page_source for indicator in dashboard_indicators):
                    return True
                time.sleep(1)
            except Exception:
                time.sleep(1)
                continue
        
        return False
    
    def navigate_to_manuscripts(self) -> bool:
        """Navigate to manuscripts section."""
        try:
            logger.info("ðŸ“‚ Navigating to manuscripts...")
            
            # XPath selectors for SIFIN dashboard elements
            dashboard_selectors = [
                "//tbody[@role='assoc_ed']",
                "//tr[@class='ndt_task']", 
                "//a[@class='ndt_task_link']",
                "//a[contains(text(), 'Associate Editor')]",
                "//a[contains(text(), 'Manuscripts')]",
                "//a[contains(@href, 'assoc_ed')]"
            ]
            
            manuscript_element = None
            for selector in dashboard_selectors:
                try:
                    manuscript_element = self.wait.until(
                        EC.element_to_be_clickable((By.XPATH, selector))
                    )
                    logger.info(f"âœ… Found dashboard element: {selector}")
                    break
                except TimeoutException:
                    continue
            
            if manuscript_element:
                manuscript_element.click()
                time.sleep(3)
                logger.info("âœ… Navigated to manuscripts section")
                return True
            else:
                logger.warning("âš ï¸ No manuscript navigation found - analyzing current page")
                return self._analyze_current_page()
                
        except Exception as e:
            logger.error(f"âŒ Failed to navigate to manuscripts: {e}")
            return False
    
    def _analyze_current_page(self) -> bool:
        """Analyze current page for manuscript data."""
        try:
            page_source = self.driver.page_source.lower()
            
            # Check for manuscript-related content
            manuscript_indicators = [
                "manuscript",
                "submission", 
                "author",
                "referee",
                "review",
                "sifin"
            ]
            
            found_indicators = sum(1 for indicator in manuscript_indicators 
                                 if indicator in page_source)
            
            if found_indicators >= 3:
                logger.info("âœ… Current page contains manuscript data")
                return True
            else:
                logger.warning("âš ï¸ Page doesn't appear to contain manuscript data")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Page analysis failed: {e}")
            return False
    
    def extract_manuscripts(self) -> List[Dict[str, Any]]:
        """Extract manuscript data from current page."""
        manuscripts = []
        
        try:
            logger.info("ðŸ“Š Extracting manuscript data...")
            
            # Multiple extraction strategies
            manuscripts.extend(self._extract_from_tables())
            manuscripts.extend(self._extract_from_lists())
            manuscripts.extend(self._extract_from_text())
            manuscripts.extend(self._extract_from_email_timeline())
            
            # Remove duplicates
            unique_manuscripts = []
            seen_ids = set()
            
            for manuscript in manuscripts:
                manuscript_id = manuscript.get('id', '')
                if manuscript_id and manuscript_id not in seen_ids:
                    seen_ids.add(manuscript_id) 
                    unique_manuscripts.append(manuscript)
            
            logger.info(f"âœ… Extracted {len(unique_manuscripts)} unique manuscripts")
            return unique_manuscripts
            
        except Exception as e:
            logger.error(f"âŒ Manuscript extraction failed: {e}")
            return []
    
    def _extract_from_tables(self) -> List[Dict[str, Any]]:
        """Extract manuscripts from HTML tables."""
        manuscripts = []
        
        try:
            tables = self.driver.find_elements(By.TAG_NAME, "table")
            
            for table in tables:
                table_text = table.text.lower()
                if any(word in table_text for word in ['manuscript', 'submission', 'sifin']):
                    manuscripts.extend(self._parse_manuscript_table(table))
            
        except Exception as e:
            logger.warning(f"âš ï¸ Table extraction error: {e}")
        
        return manuscripts
    
    def _extract_from_lists(self) -> List[Dict[str, Any]]:
        """Extract manuscripts from HTML lists."""
        manuscripts = []
        
        try:
            lists = self.driver.find_elements(By.TAG_NAME, "ul") + \
                   self.driver.find_elements(By.TAG_NAME, "ol")
            
            for list_elem in lists:
                list_text = list_elem.text.lower()
                if any(word in list_text for word in ['manuscript', 'submission', 'sifin']):
                    manuscripts.extend(self._parse_manuscript_list(list_elem))
            
        except Exception as e:
            logger.warning(f"âš ï¸ List extraction error: {e}")
        
        return manuscripts
    
    def _extract_from_text(self) -> List[Dict[str, Any]]:
        """Extract manuscripts from page text using patterns."""
        manuscripts = []
        
        try:
            page_text = self.driver.page_source
            
            # Patterns for SIFIN manuscript IDs
            sifin_patterns = [
                r'SIFIN[-_]?\d{4}[-_]?\d{4,6}',
                r'SF\d{2}[-_]?\d{4}',
                r'\d{2}[-_]?\d{4}[-_]?\d{3,6}'
            ]
            
            for pattern in sifin_patterns:
                manuscript_ids = re.findall(pattern, page_text, re.IGNORECASE)
                
                for manuscript_id in manuscript_ids:
                    manuscript = {
                        'id': manuscript_id.upper(),
                        'title': f'[Extracted] Manuscript {manuscript_id}',
                        'journal': 'SIFIN',
                        'status': 'under_review',
                        'authors': [],
                        'referees': [],
                        'extraction_method': 'text_pattern'
                    }
                    manuscripts.append(manuscript)
            
        except Exception as e:
            logger.warning(f"âš ï¸ Text extraction error: {e}")
        
        return manuscripts
    
    def _extract_from_email_timeline(self) -> List[Dict[str, Any]]:
        """Extract manuscripts using email timeline method."""
        manuscripts = []
        
        try:
            # This would integrate with email mining system
            logger.info("ðŸ“§ Attempting email timeline extraction...")
            
            # Placeholder for email-based extraction
            # This would search for referee invitation emails, review requests, etc.
            # Integration point with existing email mining system
            
            logger.info("   â„¹ï¸ Email timeline extraction requires integration with Gmail API")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Email timeline extraction error: {e}")
        
        return manuscripts
    
    def _parse_manuscript_table(self, table) -> List[Dict[str, Any]]:
        """Parse manuscript data from a table element."""
        manuscripts = []
        
        try:
            rows = table.find_elements(By.TAG_NAME, "tr")
            
            for row in rows[1:]:  # Skip header
                cells = row.find_elements(By.TAG_NAME, "td")
                if len(cells) >= 2:
                    manuscript_id = self._extract_manuscript_id(cells[0].text)
                    if manuscript_id:
                        manuscript = {
                            'id': manuscript_id,
                            'title': cells[1].text if len(cells) > 1 else '',
                            'journal': 'SIFIN',
                            'status': cells[2].text if len(cells) > 2 else 'unknown',
                            'authors': [],
                            'referees': [],
                            'extraction_method': 'table_parsing'
                        }
                        manuscripts.append(manuscript)
        
        except Exception as e:
            logger.warning(f"âš ï¸ Table parsing error: {e}")
        
        return manuscripts
    
    def _parse_manuscript_list(self, list_elem) -> List[Dict[str, Any]]:
        """Parse manuscript data from a list element."""
        manuscripts = []
        
        try:
            items = list_elem.find_elements(By.TAG_NAME, "li")
            
            for item in items:
                manuscript_id = self._extract_manuscript_id(item.text)
                if manuscript_id:
                    manuscript = {
                        'id': manuscript_id,
                        'title': item.text,
                        'journal': 'SIFIN',
                        'status': 'under_review',
                        'authors': [],
                        'referees': [],
                        'extraction_method': 'list_parsing'
                    }
                    manuscripts.append(manuscript)
        
        except Exception as e:
            logger.warning(f"âš ï¸ List parsing error: {e}")
        
        return manuscripts
    
    def _extract_manuscript_id(self, text: str) -> Optional[str]:
        """Extract manuscript ID from text."""
        patterns = [
            r'SIFIN[-_]?\d{4}[-_]?\d{4,6}',
            r'SF\d{2}[-_]?\d{4}',
            r'\d{2}[-_]?\d{4}[-_]?\d{3,6}'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group().upper()
        
        return None
    
    def extract_all_manuscripts(self, **kwargs) -> List[Dict[str, Any]]:
        """Main extraction method - extract all manuscripts."""
        try:
            logger.info(f"ðŸš€ Starting {self.journal_name} extraction...")
            
            # Setup driver
            if not self.setup_driver():
                return []
            
            # Authenticate
            if not self.authenticate_with_orcid():
                logger.error("âŒ Authentication failed")
                return []
            
            # Navigate to manuscripts
            if not self.navigate_to_manuscripts():
                logger.error("âŒ Failed to access manuscripts")
                return []
            
            # Extract manuscripts
            manuscripts = self.extract_manuscripts()
            
            # Store results
            self.manuscripts = manuscripts
            self.extraction_metadata = {
                'journal_code': self.journal_code,
                'journal_name': self.journal_name,
                'total_manuscripts': len(manuscripts),
                'extraction_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'extraction_method': 'selenium_firefox'
            }
            
            # Save results
            self._save_results()
            
            logger.info(f"ðŸŽ‰ {self.journal_name} extraction completed!")
            logger.info(f"   ðŸ“Š Extracted {len(manuscripts)} manuscripts")
            
            return manuscripts
            
        except Exception as e:
            logger.error(f"âŒ Extraction failed: {e}")
            return []
        
        finally:
            self._cleanup()
    
    def _save_results(self):
        """Save extraction results to file."""
        try:
            timestamp = time.strftime('%Y%m%d_%H%M%S')
            output_file = f"sifin_extraction_{timestamp}.json"
            
            results = {
                'metadata': self.extraction_metadata,
                'manuscripts': self.manuscripts
            }
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ðŸ’¾ Results saved to: {output_file}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to save results: {e}")
    
    def _cleanup(self):
        """Clean up resources."""
        try:
            if self.driver:
                self.driver.quit()
                logger.info("ðŸ§¹ Driver cleanup completed")
        except Exception as e:
            logger.warning(f"âš ï¸ Cleanup warning: {e}")
    
    def get_extraction_summary(self) -> Dict[str, Any]:
        """Get summary of extraction results."""
        return {
            'journal_code': self.journal_code,
            'journal_name': self.journal_name,
            'total_manuscripts': len(self.manuscripts),
            'total_referees': sum(len(m.get('referees', [])) for m in self.manuscripts),
            'extraction_status': 'completed' if self.manuscripts else 'failed',
            'metadata': self.extraction_metadata
        }

def main():
    """Test the SIFIN extractor."""
    extractor = SIFINExtractor()
    manuscripts = extractor.extract_all_manuscripts()
    
    print(f"\nðŸ“Š Extraction Summary:")
    print(f"   Journal: {extractor.journal_name}")
    print(f"   Manuscripts: {len(manuscripts)}")
    
    if manuscripts:
        print(f"\nðŸ“„ Sample manuscript:")
        print(json.dumps(manuscripts[0], indent=2))

if __name__ == "__main__":
    main()